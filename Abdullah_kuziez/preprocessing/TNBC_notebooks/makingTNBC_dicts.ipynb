{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa41700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20311 symbol-to-uniprot mappings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_66484\\2635805513.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This notebook is the central workstation for figuring out how best to preprocess the data;\n",
    "Author: Abdullah Kuziez\n",
    "Dependencies: making_cellbox_files.py, graphing_fxns.py, filtering_functions.py,\n",
    "\n",
    "General philosophy: the first section of the codebase structures the data into dictionaries of data_by_cell_line, \n",
    "once this is acheived, the filtering and plotting functions should be able to be applied to any dataset with the same structure\n",
    "\n",
    "Dictionary structured as {cell_line: dataframe_for_cell_line,....}\n",
    "\n",
    "Dataframe for cell line structured:\n",
    "Rows=experiments(averaged together across replicates\n",
    "Columns=protein expression levels+phenotypes+metadata(identified by the regex prefix meta_))\n",
    "\n",
    "Supporting dataframes/dictionaries of control values and coefficients of variation are also made to facilitate transformation and filtering\n",
    "The code checks for completeness of experiments and proteins, and removes outliers and low coefficient of variation proteins\"\"\"\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list, fcluster\n",
    "from collections import defaultdict\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "#//////////////////////////////////////////Part 1: loading in data //////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "with open(r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Experiments\\raw_data\\TNBC_set\\symbol_to_uniprot.json', 'r') as f:\n",
    "    symbol_to_uniprot = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(symbol_to_uniprot)} symbol-to-uniprot mappings\")\n",
    "\n",
    "data=pd.read_csv(\n",
    "r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Experiments\\raw_data\\TNBC_set\\PTV1_protein_matrix_test.cleaned.tsv',\n",
    "index_col=0,sep='\\t')\n",
    "\n",
    "viability_raw=pd.read_excel(\n",
    "r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Experiments\\raw_data\\TNBC_set\\cell_viability_sampleinfo_for_chris.xlsx', \n",
    "sheet_name=0)\n",
    "\n",
    "screen_info = pd.read_excel(\n",
    "    r\"C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Experiments\\raw_data\\TNBC_set\\PTV1_sample_info_test.xlsx\", \n",
    "    sheet_name=0)  # First sheet is single perturbation info\n",
    "\n",
    "\n",
    "#//////////////////////////////////////////Part 2: structuring data //////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "#making data_by_cell_line_raw; control_data_by_cell_line; control_data_by_cell_line_coeffvar:\n",
    "data_T=data.transpose()\n",
    "data_T['Sample_ID']=data_T.index\n",
    "data_and_screen_info=pd.merge(data_T,screen_info,on='Sample_ID',how='left')\n",
    "data_and_screen_info_and_viability = pd.merge(data_and_screen_info, viability_raw, on='Sample_ID', how='left')\n",
    "\n",
    "#averaging over replicates:(pandas mean ignores NaN's)\n",
    "#preserving the control rows since they drop out for some reason:\n",
    "control_rows=data_and_screen_info_and_viability[data_and_screen_info_and_viability['pert_id']=='no']\n",
    "r_conts = control_rows.copy()\n",
    "data_and_screen_info_and_viability_grouped = (\n",
    "    data_and_screen_info_and_viability\n",
    "    .groupby(['pert_id', 'Cell', 'pert_time_x'])\n",
    "    .mean(numeric_only=True)\n",
    "    .reset_index()\n",
    ")\n",
    "r_conts.loc[r_conts['pert_id'] == 'no', 'pert_id'] = 'control'\n",
    "r_conts_grouped_mean=r_conts.groupby(['pert_id', 'cell_line']).mean(numeric_only=True).reset_index()\n",
    "#dropping unneeded columns:\n",
    "data_dropped=data_and_screen_info_and_viability_grouped.drop(columns=['BioRep_y','pert_time_y'])\n",
    "\n",
    "#getting coeff var for control data for filtering:\n",
    "intermediate=r_conts.groupby(['cell_line']).std(numeric_only=True)\n",
    "inter_idx=intermediate.index\n",
    "r_conts_grouped_std=intermediate.reset_index()\n",
    "# Calculate coefficient of variation, but if mean exists and std is NaN, set coeff_var to 3\n",
    "mean_df = r_conts_grouped_mean.select_dtypes(include=[float, int])\n",
    "std_df = r_conts_grouped_std.select_dtypes(include=[float, int])\n",
    "coeff_var = std_df / mean_df\n",
    "\n",
    "# Find where mean is not NaN and std is NaN, set coeff_var to 3 in those places\n",
    "mask = mean_df.notna() & std_df.isna()\n",
    "coeff_var[mask] = -.25\n",
    "coeff_var['cell_line']=inter_idx\n",
    "\n",
    "#dropping the irrelevant timepoints, (6 and 48)\n",
    "data_dropped=data_dropped[data_dropped['pert_time_x']==6]\n",
    "\n",
    "#//////////metadata codeblock\n",
    "# Move the first three columns to the end of data_dropped\n",
    "first_three_cols = data_dropped.columns[:3]\n",
    "other_cols = data_dropped.columns[3:]\n",
    "data_dropped = data_dropped.loc[:, list(other_cols) + list(first_three_cols)]\n",
    "# Rename the last 10 columns of data_dropped by adding 'meta_' as a prefix\n",
    "cols = list(data_dropped.columns)\n",
    "last_9 = cols[-8:]\n",
    "new_last_9 = ['meta_' + col for col in last_9]\n",
    "rename_dict = dict(zip(last_9, new_last_9))\n",
    "data_dropped = data_dropped.rename(columns=rename_dict)\n",
    "#////////////////////////\n",
    "\n",
    "#generating the dictionaries by cell line\n",
    "data_by_cell_line_raw={}\n",
    "control_data_by_cell_line={}\n",
    "control_data_by_cell_line_coeffvar={}\n",
    "cell_lines=pd.unique(data_and_screen_info_and_viability_grouped['Cell'])\n",
    "for cell in cell_lines:\n",
    "    data_by_cell_line_raw[cell]=data_dropped[data_dropped['meta_Cell']==cell]\n",
    "    control_data_by_cell_line[cell]=r_conts_grouped_mean[r_conts_grouped_mean['cell_line']==cell]\n",
    "    control_data_by_cell_line_coeffvar[cell]=coeff_var[coeff_var['cell_line']==cell]\n",
    "    control_data_by_cell_line_coeffvar[cell].drop(columns=['cell_line'],inplace=True)\n",
    "\n",
    "#//////////////////////////////////////////Part 3: renaming from pert-ID to drug name to group trials //////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#making drug_pert_id_targets_dict\n",
    "drugs_and_targets = pd.read_csv(\n",
    "    r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Experiments\\raw_data\\TNBC_set\\ptv1_unique_drug_names.csv'\n",
    ")\n",
    "drugs_and_targets.rename(columns={'original_drug_names': 'pert_name'}, inplace=True)\n",
    "drugs_and_targets.dropna(inplace=True,subset=['pert_name'])\n",
    "\n",
    "# Read and process drugs_and_pert_ids\n",
    "drugs_and_pert_ids = pd.read_csv(\n",
    "    r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Experiments\\raw_data\\TNBC_set\\PTV1_sample_info_test.csv'\n",
    ")\n",
    "\n",
    "drugs_and_pert_ids = (\n",
    "    drugs_and_pert_ids\n",
    "    .drop_duplicates(subset=['pert_id'])\n",
    "    .drop_duplicates(subset=['pert_name'])\n",
    "    .loc[:, ['pert_id', 'pert_name']]\n",
    "    .assign(pert_id=lambda df: df['pert_id'].str.replace('#', ''))\n",
    "    .dropna()\n",
    "    .assign(pert_id=lambda df: df['pert_id'].astype(int))\n",
    "    .sort_values('pert_id')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Merge and drop unnecessary columns\n",
    "drugs_pert_ids_targets = (\n",
    "    pd.merge(drugs_and_pert_ids, drugs_and_targets, on='pert_name', how='left')\n",
    "    .drop(columns=['corrected_drug_name', 'drugbank_targets_manual_check'], errors='ignore')\n",
    ")\n",
    "\n",
    "# Build dictionary mapping pert_id and pert_name to list of targets\n",
    "drug_pert_id_targets_dict = {}\n",
    "for _, row in drugs_pert_ids_targets.iterrows():\n",
    "    targets = []\n",
    "    if pd.notnull(row.get('target_uniprot_ids')):\n",
    "        targets = [t.strip() for t in str(row['target_uniprot_ids']).split(',') if t.strip()]\n",
    "    drug_pert_id_targets_dict[row['pert_id']] = targets\n",
    "    drug_pert_id_targets_dict[row['pert_name']] = targets\n",
    "\n",
    "\n",
    "#//////////////////////////////////////////Part 4: making targeted_prots_raw and non_targeted_prots_raw: //////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#making targeted_prots_raw and non_targeted_prots_raw:\n",
    "graph_flag=False\n",
    "#Main method-essential filtering:\n",
    "# graph_flag = False  #set to true to plot in the filter lines\n",
    "cell_lines=['HS578T','HCC70','BT549','MDA-MB-453','MCF7','DU4475']\n",
    "\n",
    "#basic completeness filters #TODO graphs are broken but that's fine\n",
    "targeted_prots_raw={}\n",
    "non_targeted_prots_raw={}\n",
    "all_targeted_prots=[item for sublist in drug_pert_id_targets_dict.values() for item in sublist]\n",
    "\n",
    "for cell in cell_lines:\n",
    "    meta_cols=data_by_cell_line_raw[cell].columns[data_by_cell_line_raw[cell].columns.str.contains('meta_')]\n",
    "    intersection=list(set(all_targeted_prots).intersection(set(data_by_cell_line_raw[cell].columns)))\n",
    "\n",
    "\n",
    "    targeted_prots_raw[cell] = data_by_cell_line_raw[cell][list(intersection) + list(meta_cols)]\n",
    "    \n",
    "    non_targeted_prots_raw[cell]=data_by_cell_line_raw[cell].drop(columns=intersection)\n",
    "\n",
    "\n",
    "#//////////////////////////////////////////Part 5: writing data to files///////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Set a directory for intermediate files\n",
    "intermediate_dir = Path(\"intermediate_files_TNBC/6hr\")\n",
    "intermediate_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save data_by_cell_line_raw, control_data_by_cell_line, control_data_by_cell_line_coeffvar, targeted_prots_raw, non_targeted_prots_raw\n",
    "with open(intermediate_dir / \"data_by_cell_line_raw_6hr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_by_cell_line_raw, f)\n",
    "with open(intermediate_dir / \"control_data_by_cell_line_6hr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(control_data_by_cell_line, f)\n",
    "with open(intermediate_dir / \"control_data_by_cell_line_coeffvar_6hr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(control_data_by_cell_line_coeffvar, f)\n",
    "with open(intermediate_dir / \"targeted_prots_raw_6hr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(targeted_prots_raw, f)\n",
    "with open(intermediate_dir / \"non_targeted_prots_raw_6hr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(non_targeted_prots_raw, f)\n",
    "with open(intermediate_dir / \"cell_lines_6hr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cell_lines, f)\n",
    "with open(intermediate_dir / \"drug_pert_id_targets_dict_6hr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(drug_pert_id_targets_dict, f)\n",
    "\n",
    "# Save symbol_to_uniprot as JSON\n",
    "with open(intermediate_dir / \"symbol_to_uniprot.json\", \"w\") as f:\n",
    "    json.dump(symbol_to_uniprot, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafcc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
