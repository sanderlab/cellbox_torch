{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_completeness(prot_data, prot_info, completeness_threshold=0.8, metadata_indices=None):\n",
    "    \"\"\"\n",
    "    Filters proteins based on completeness threshold.\n",
    "    \n",
    "    Args:\n",
    "        prot_data: DataFrame containing protein expression data\n",
    "        prot_info: DataFrame containing protein metadata\n",
    "        completeness_threshold: Minimum proportion of non-NaN values required (default: 0.8)\n",
    "        metadata_indices: List of column indices that contain metadata\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with proteins filtered by completeness\n",
    "    \"\"\"\n",
    "    # Separate metadata and expression data\n",
    "    meta, expr = separate_metadata(prot_data, metadata_indices)\n",
    "    \n",
    "    # Calculate completeness for each protein column\n",
    "    completeness = expr.notna().mean()\n",
    "    \n",
    "    # Filter proteins that meet the completeness threshold\n",
    "    complete_proteins = completeness[completeness >= completeness_threshold].index.tolist()\n",
    "    \n",
    "    # Filter the expression data to only include complete proteins\n",
    "    filtered_expr = expr[complete_proteins]\n",
    "    \n",
    "    # Update protein info to match filtered dataset\n",
    "    filtered_info = prot_info[prot_info['proteins'].isin(complete_proteins)]\n",
    "    \n",
    "    # Recombine metadata and filtered expression data\n",
    "    filtered_data = recombine_data(meta, filtered_expr)\n",
    "    \n",
    "    print(f\"Filtered from {len(expr.columns)} to {len(filtered_expr.columns)} proteins\")\n",
    "    print(f\"Completeness threshold: {completeness_threshold}\")\n",
    "    \n",
    "    return filtered_data, filtered_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_control_values(prot_data, control_id='control', metadata_indices=None):\n",
    "    \"\"\"\n",
    "    Filters columns to only keep those where the control sample has a value.\n",
    "    \n",
    "    Args:\n",
    "        prot_data: DataFrame containing protein expression data\n",
    "        control_id: Identifier for control samples (default: 'control')\n",
    "        metadata_indices: List of column indices that contain metadata\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with only columns that have control values\n",
    "    \"\"\"\n",
    "    # Get control row by finding the row with control pert_id before separating metadata\n",
    "    control_row = prot_data.loc[prot_data['pert_id'] == control_id]\n",
    "    \n",
    "    # Separate metadata and expression data\n",
    "    meta, expr = separate_metadata(prot_data, metadata_indices)\n",
    "    \n",
    "    # Get protein columns (excluding pert_id)\n",
    "    protein_cols = expr.columns\n",
    "    \n",
    "    # Check which columns have values in the control row\n",
    "    valid_columns = []\n",
    "    for col in protein_cols:\n",
    "        if not pd.isna(control_row[col].iloc[0]):\n",
    "            valid_columns.append(col)\n",
    "    \n",
    "    # Filter dataset to only include columns that had entries in control row\n",
    "    filtered_expr = expr[valid_columns]\n",
    "    \n",
    "    # Recombine with metadata and expression data\n",
    "    filtered_data = recombine_data(meta, filtered_expr)\n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_log_ratios(prot_data, control_id='control',metadata_indices=None):\n",
    "    \"\"\"\n",
    "    Converts protein expression data to log ratios relative to control samples.\n",
    "    Args:\n",
    "        prot_data: DataFrame containing protein expression data\n",
    "        control_id: Identifier for control samples (default: 'control')\n",
    "        metadata_indices: List of column indices that contain metadata\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame containing log ratios\n",
    "    \"\"\"\n",
    "    # Separate metadata and expression data\n",
    "    meta, expr = separate_metadata(prot_data, metadata_indices)\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_cols = expr.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Calculate mean control values for numeric columns only\n",
    "    # Use meta to identify control samples since pert_id is in metadata\n",
    "    control_mask = meta['pert_id'] == control_id\n",
    "    control_means = expr[control_mask][numeric_cols].mean()\n",
    "    \n",
    "    # Calculate log ratios for all samples including control\n",
    "    log_ratios = expr.copy()\n",
    "    \n",
    "    # Calculate log ratios for numeric columns\n",
    "    for col in numeric_cols:\n",
    "        log_ratios[col] = np.log10(expr[col] / control_means[col])\n",
    "    \n",
    "    print(f\"Converted {len(expr)} samples to log ratios\")\n",
    "    \n",
    "    # Recombine with metadata\n",
    "    return recombine_data(meta, log_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targeted_proteins(prot_data, prot_info, id_key='Uniprot.ID'):\n",
    "    \"\"\"\n",
    "    Identifies proteins that are targeted by drugs in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        prot_data: DataFrame containing protein expression data\n",
    "        prot_info: DataFrame containing protein metadata\n",
    "        id_key: Column name containing target IDs (default: 'Uniprot.ID')\n",
    "    \n",
    "    Returns:\n",
    "        List of protein IDs that are targeted by drugs\n",
    "    \"\"\"\n",
    "    # Get all unique uniprot ID's for each trial from data.csv\n",
    "    #This is from data.csv file and the uniprot ID says which proteins are targeted by drugs\n",
    "    all_targets = prot_data[id_key].dropna().unique()\n",
    "    \n",
    "    # Split targets that may be comma or semicolon-separated and flatten the list\n",
    "    target_list = []\n",
    "    #if there are multiple targets, split them by comma or semicolon, then convert to uppercase and get rid of whitespace and then add to target_list\n",
    "    for targets in all_targets:\n",
    "        if isinstance(targets, str):\n",
    "            target_list.extend([t.strip().upper() for t in re.split(r'[;,]', targets)])\n",
    "    \n",
    "    # Get unique targets, (just looking at the set which gets rid of duplicates)\n",
    "    unique_targets = list(set(target_list))\n",
    "    \n",
    "    # Filter to only include targets that exist in our protein measurements\n",
    "    valid_targets = [t for t in unique_targets if t in prot_data.columns]\n",
    "    \n",
    "    print(f\"Found {len(valid_targets)} unique targeted proteins out of {len(unique_targets)} total targets\")\n",
    "    return valid_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_proteins_by_variability(log_ratios, protein_cols):\n",
    "    \"\"\"\n",
    "    Sorts proteins based on their variability across samples.\n",
    "    \n",
    "    Args:\n",
    "        log_ratios: DataFrame containing log ratio values\n",
    "        protein_cols: List of protein column names\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with proteins sorted by their standard deviation\n",
    "    \"\"\"\n",
    "    # Calculate standard deviation for each protein\n",
    "    protein_std = log_ratios[protein_cols].std()\n",
    "    \n",
    "    # Sort proteins by standard deviation in descending order\n",
    "    sorted_proteins = protein_std.sort_values(ascending=False)\n",
    "    \n",
    "    # Create DataFrame with protein names and their standard deviations\n",
    "    variability_df = pd.DataFrame({\n",
    "        'protein': sorted_proteins.index,\n",
    "        'std_dev': sorted_proteins.values\n",
    "    })\n",
    "    \n",
    "    print(f\"Sorted {len(protein_cols)} proteins by variability\")\n",
    "    return variability_df\n",
    "\n",
    "# Example usage:\n",
    "# variability_df = sort_proteins_by_variability(log_ratios, protein_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_data(df_raw, meta_data_cols):\n",
    "    \"\"\"\n",
    "    Apply transformations to the raw data including extracting cell viability and reorganizing columns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_raw : pandas.DataFrame\n",
    "        Raw input dataframe containing all data\n",
    "    meta_data_cols : list\n",
    "        List of column indices for metadata columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Reorganized dataframe with protein data first, then cell viability, then metadata\n",
    "    \"\"\"\n",
    "    # Extract cell viability and organize data columns\n",
    "    cell_viability = df_raw['Cell_viability%_(cck8Drug-blk)/(control-blk)*100']\n",
    "    metadata_cols = df_raw.columns[meta_data_cols]\n",
    "    non_metadata_cols = df_raw.columns.difference(metadata_cols)\n",
    "    non_metadata_cols = non_metadata_cols.difference(['Cell_viability%_(cck8Drug-blk)/(control-blk)*100'])\n",
    "\n",
    "    # Reorganize dataframe with protein data first, then cell viability, then metadata\n",
    "    df_meta_data_at_end = pd.concat([\n",
    "        df_raw[non_metadata_cols],  # Protein expression data\n",
    "        cell_viability,            # Cell viability\n",
    "        df_raw[metadata_cols]      # Metadata columns\n",
    "    ], axis=1)\n",
    "    \n",
    "    return df_meta_data_at_end\n",
    "\n",
    "def separate_metadata(data_df, metadata_indices=None):\n",
    "    \"\"\"\n",
    "    Separates metadata columns from protein expression data based on provided indices.\n",
    "    Expression columns are all columns not in metadata_indices.\n",
    "    \n",
    "    Args:\n",
    "        data_df: DataFrame containing both metadata and protein expression data\n",
    "        metadata_indices: List of column indices for metadata (optional)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (metadata_df, expression_df) containing separated DataFrames\n",
    "    \"\"\"\n",
    "    if metadata_indices is None:\n",
    "        # Fallback to original behavior if no indices provided\n",
    "        metadata_cols = data_df.select_dtypes(include=['object', 'bool']).columns\n",
    "        expression_cols = data_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    else:\n",
    "        # Use provided indices to split columns\n",
    "        metadata_cols = data_df.columns[metadata_indices]\n",
    "        expression_cols = data_df.columns[~data_df.columns.isin(metadata_cols)]\n",
    "    \n",
    "    # Split the data\n",
    "    metadata_df = data_df[metadata_cols].copy()\n",
    "    expression_df = data_df[expression_cols].copy()\n",
    "    \n",
    "    return metadata_df, expression_df\n",
    "\n",
    "def recombine_data(metadata_df, expression_df):\n",
    "    \"\"\"\n",
    "    Recombines metadata and expression data into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        metadata_df: DataFrame containing metadata\n",
    "        expression_df: DataFrame containing protein expression data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with recombined data\n",
    "    \"\"\"\n",
    "    # Ensure indices match\n",
    "    if not metadata_df.index.equals(expression_df.index):\n",
    "        raise ValueError(\"Metadata and expression data must have matching indices\")\n",
    "    \n",
    "    # Combine the data, the order ensures that the metadata is at the end\n",
    "    combined_df = pd.concat([expression_df, metadata_df], axis=1)\n",
    "    \n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pert_id_to_targets_dict(prot_log):\n",
    "    #make blank dictionary\n",
    "    pert_id_to_targets_dict={}\n",
    "    #get the pert id and uniprot id from the prot_log dataframe\n",
    "    for index, row in prot_log.iterrows():\n",
    "        pert_id=row['pert_id']\n",
    "        uniprot_id=row['Uniprot.ID']\n",
    "        id_list=[]\n",
    "        #split the uniprot ID by comma or semicolon, doing some basic checks to make sure it's not empty:\n",
    "        if uniprot_id is not np.nan:\n",
    "            if 'not' not in str(uniprot_id).lower():\n",
    "                id_list.extend([t.strip().upper() for t in re.split(r'[;,]', uniprot_id)])\n",
    "        #associate all the uniprot ID's with the pert id in the dict.\n",
    "        pert_id_to_targets_dict[pert_id]=id_list\n",
    "    return pert_id_to_targets_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_activity_nodes(targeted_proteins_with_metadata,pert_id_to_targets_dict):\n",
    "    activity_nodes=targeted_proteins_with_metadata.copy()\n",
    "    #scan through each protein column\n",
    "    for protein in targeted_proteins_with_metadata.columns:\n",
    "\n",
    "        #scan through each row and get the pert_id, then look it up in the dictionary to see if the protein is targeted;\n",
    "        for index, row in targeted_proteins_with_metadata.iterrows():\n",
    "\n",
    "            pert_id=row['pert_id']\n",
    "\n",
    "            #check if the pert_id is in the pert_ID_list\n",
    "            if pert_id in pert_id_to_targets_dict.keys():\n",
    "                #check if the protein is in the dictionary\n",
    "                if protein in pert_id_to_targets_dict[pert_id]:\n",
    "                    pass\n",
    "                else:\n",
    "                    if protein in activity_nodes.columns:\n",
    "                        activity_nodes.loc[index,protein]=0\n",
    "\n",
    "    #cleave off last 12 columns for metadata:\n",
    "    activity_nodes=activity_nodes.iloc[:,:-12]\n",
    "    return activity_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targeted_indices(targeted_proteins_with_metadata):\n",
    "    protein_list=targeted_proteins_with_metadata.columns\n",
    "    targeted_indices = []\n",
    "    #first check that it is proteins:\n",
    "    for index, Uniprots in enumerate(targeted_proteins_with_metadata['Uniprot.ID']):\n",
    "        if Uniprots is not np.nan:\n",
    "            if 'not' not in str(Uniprots).lower():\n",
    "                id_list=[]\n",
    "                id_list.extend([t.strip().upper() for t in re.split(r'[;,]', Uniprots)])\n",
    "                #then check that the protein is in the list of targeted proteins:\n",
    "                for i in id_list:\n",
    "                    if i in protein_list:\n",
    "                        targeted_indices.append(index)\n",
    "                        break\n",
    "    return targeted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cellbox takes in three files: expr.csv, pert.csv, node_Index.csv\n",
    "#expr.csv is the expression data, of size drug trials x(proteins+phenotypes+activity nodes)\n",
    "#pert.csv is the perturbation data, of size drug trials x(proteins+phenotypes+activity nodes); the proteins and phenotypes are zeroed out\n",
    "#the activity nodes indicate the activity of each protein in each drug trial, and so therefore should be of size #of targeted proteins, \n",
    "#these are activated.\n",
    "\n",
    "def make_cellbox_files(prot_log, acti_df, file_prefix, file_path):\n",
    "    \"\"\"\n",
    "    Creates CellBox input files from processed data.\n",
    "    \n",
    "    Args:\n",
    "        prot_log: DataFrame containing log ratios\n",
    "        acti_df: DataFrame containing activity nodes\n",
    "        file_prefix: Prefix for output files\n",
    "        file_path: Path to save output files\n",
    "    \n",
    "    Returns: cellbox_files\n",
    "    \"\"\"\n",
    "\n",
    "    expr_csv = prot_log.merge(acti_df, left_index=True, right_index=True)\n",
    "\n",
    "    # Create perturbation data\n",
    "    zeros_pert = pd.DataFrame(np.zeros_like(prot_log), columns=prot_log.columns, index=prot_log.index)\n",
    "    acti_df_arctanh = pd.DataFrame(\n",
    "        np.arctanh(acti_df.to_numpy().astype(float)),\n",
    "        columns=acti_df.columns, index=acti_df.index\n",
    "    )\n",
    "    pert_csv = pd.merge(zeros_pert, acti_df_arctanh, left_index=True, right_index=True)\n",
    "\n",
    "    # Create node index\n",
    "    columns = pert_csv.columns.tolist()\n",
    "    node_index_csv = pd.DataFrame({\"A\": columns})\n",
    "\n",
    "    # Save files\n",
    "    expr_csv.to_csv(\n",
    "        (file_path + file_prefix + \"expr.csv\"),\n",
    "        header=False,\n",
    "        index=False\n",
    "    )\n",
    "    pert_csv.to_csv(\n",
    "        (file_path + file_prefix + \"pert.csv\"),\n",
    "        header=False,\n",
    "        index=False\n",
    "    )\n",
    "    node_index_csv.to_csv(\n",
    "        (file_path + file_prefix + \"node_Index.csv\"),\n",
    "        sep=\" \",\n",
    "        header=False,\n",
    "        index=False\n",
    "    )\n",
    "    return expr_csv, pert_csv, node_index_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This file contains code to conduct the preprocessing for data\n",
    "# and has been functionalized to allow for more flexible data handling\n",
    "# Derived from Elastic_net.ipynb\n",
    "# Key parameters are included below:\n",
    "# 1.Filter by completeness; (check the number of absent entries and filter proteins below a certain threshold)\n",
    "# 5.Apply a signal to noise filter to remove proteins that have a high signal to noise ratio\n",
    "# 2.change expression values into log ratios as compared to the control test\n",
    "# 3.Fill in the missing values using various methods (1st method is to fill in with the mean of the column)\n",
    "# 3.Pull out proteins that are targeted by drugs\n",
    "# 4.Sort proteins according to how much they vary\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start main method:\n",
    "#reading in data\n",
    "#NOTE Things to change for different datasets:\n",
    "data_path=r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\preprocessing\\data.csv'\n",
    "prot_info_path=r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\preprocessing\\prots_info.csv'\n",
    "df_prot_info=pd.read_csv(prot_info_path)\n",
    "df_raw=pd.read_csv(data_path)\n",
    "df_control_row = df_raw[df_raw['pert_id']=='control'] #pulls out the control row\n",
    "meta_data_cols = [0] + list(range(-12, -2))+[-1] #The metadata columns, must be changed for different datasets\n",
    "#NOTE the function explicitly pulls out cell viability, that would also need to be changed for different datasets\n",
    "df_raw=reorganize_data(df_raw, meta_data_cols)\n",
    "#applying transforms:\n",
    "#NOTE now that the metadata is at the end, we need to update the metadata indices\n",
    "meta_data_cols = range(-12,0)\n",
    "#DONE READING IN DATA AND RESHAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 8544 to 5733 proteins\n",
      "Completeness threshold: 0.95\n",
      "Converted 94 samples to log ratios\n",
      "Found 61 unique targeted proteins out of 277 total targets\n",
      "Shape of targeted proteins dataframe: (94, 73)\n"
     ]
    }
   ],
   "source": [
    "#FILTERING AND GENERATING STARTING DATA STRUCTURES\n",
    "filtered_by_completeness, filtered_by_completeness_info=filter_by_completeness(df_raw, df_prot_info,completeness_threshold=0.95,metadata_indices=meta_data_cols) \n",
    "filtered_by_control_values=filter_by_control_values(filtered_by_completeness, control_id='control',metadata_indices=meta_data_cols)\n",
    "log_ratios=convert_to_log_ratios(filtered_by_control_values, control_id='control',metadata_indices=meta_data_cols) \n",
    "\n",
    "targeted_proteins=get_targeted_proteins(log_ratios, df_prot_info) #seems like it works\n",
    "# Get the targeted proteins from the log_ratios dataframe\n",
    "targeted_proteins_df = log_ratios[targeted_proteins]\n",
    "\n",
    "# Combine with metadata columns\n",
    "targeted_proteins_with_metadata = pd.concat([\n",
    "    targeted_proteins_df,\n",
    "    log_ratios.iloc[:, meta_data_cols]\n",
    "], axis=1)\n",
    "\n",
    "# Display the shape of the resulting dataframe\n",
    "print(f\"Shape of targeted proteins dataframe: {targeted_proteins_with_metadata.shape}\")\n",
    "# targeted_proteins_with_metadata.to_csv('targeted_proteins_with_metadata.csv', index=False)\n",
    "\n",
    "pert_id_to_targets_dict=make_pert_id_to_targets_dict(targeted_proteins_with_metadata)\n",
    "\n",
    "tgt_indices=get_targeted_indices(targeted_proteins_with_metadata)\n",
    "#\n",
    "targeted_proteins_with_metadata=targeted_proteins_with_metadata.loc[tgt_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select targeted rows\n",
    "tgtd_log_ratios=log_ratios.loc[tgt_indices]\n",
    "#select targeted proteins:\n",
    "tgtd_log_ratios=tgtd_log_ratios[targeted_proteins +['Cell_viability%_(cck8Drug-blk)/(control-blk)*100']]\n",
    "tgtd_log_ratios.fillna(0,inplace=True)\n",
    "\n",
    "activity_nodes=make_activity_nodes(targeted_proteins_with_metadata,pert_id_to_targets_dict)\n",
    "activity_nodes=activity_nodes.loc[tgt_indices]\n",
    "activity_nodes.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtd_prots_cellbox=make_cellbox_files(tgtd_log_ratios,activity_nodes,\n",
    "                   file_prefix='directly_targeted_proteins',\n",
    "                   file_path=r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Data\\run1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUTTING DOWN TO ONLY ROWS WITH TARGETED PROTEINS:\n",
    "df_of_neighbors=pd.read_csv(r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Testing_encodings\\String_adjacency\\protein_neighbors_and_degrees.csv')\n",
    "filtered_log_ratios=log_ratios.loc[tgt_indices]\n",
    "second_deg_neighbors=df_of_neighbors['second_order'].tolist()\n",
    "second_deg_neighbors_in_prots = [neighbor for neighbor in second_deg_neighbors if neighbor in filtered_log_ratios.columns]\n",
    "filtered_log_ratios=filtered_log_ratios[second_deg_neighbors_in_prots +['Cell_viability%_(cck8Drug-blk)/(control-blk)*100']]\n",
    "\n",
    "#shitty patching of holes but for now sufficient:\n",
    "filtered_log_ratios.fillna(0,inplace=True)\n",
    "activity_nodes.fillna(0,inplace=True)\n",
    "#should be good now to run the cellbox_file_maker\n",
    "x=make_cellbox_files(filtered_log_ratios,activity_nodes,\n",
    "                   file_prefix='_test_',\n",
    "                   file_path=r'C:\\Users\\abdul\\OneDrive - University of Cambridge\\Desktop\\MDRA\\cellbox_torch\\Abdullah_kuziez\\Data\\STRINGDB_encodings'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
